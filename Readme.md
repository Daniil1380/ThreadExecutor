
# Отчёт по реализации и исследованию пула потоков

## 1. Анализ производительности

Пул потоков реализован с учётом базовых требований для обработки большого количества задач. 

Одинаковые настройки (1000 задач 10 запусков):
Средний результат

Мой пул:

**9 МС 800 задач отказано, 200 выполнено, среднее время на задачу 0.045МС**

Базовый пул Java:

**4 МС 875 задач отказано, 125 выполнено, среднее время на задачу 0.05МС**

Основные моменты по сравнению со стандартными решениями (например, `ThreadPoolExecutor` из JDK, или пул потоков, использующийся в серверах приложений вроде Tomcat/Jetty):

- **Гибкость параметров:**  
  Как и стандартный `ThreadPoolExecutor`, наш пул позволяет задавать базовый размер пула (corePoolSize), максимальное число потоков (maxPoolSize), время простоя (keepAliveTime) и размер очереди. Это позволяет тонко настраивать баланс между количеством потоков и временем ожидания задач.

- **Системе распределения нагрузки:**  
  Распределение задач происходит по схеме round robin между воркерами, каждый из которых имеет собственную блокирующую очередь фиксированного размера. Такой подход обеспечивает простую схему балансировки нагрузки между потоками, однако уступает сложным алгоритмам динамической балансировки, реализованным в промышленном ПО, где учёт различных характеристик серверного оборудования и динамическая подстройка параметров идёт автоматически.

- **Производительность при больших нагрузках:**  
  При массовом выполнении задач (в нашем примере 10_000 задач) пул демонстрирует работоспособность, но наличие относительно малых очередей (queueSize = 2) может привести к частым отказам при приеме задач, если все воркеры заняты. 

## 2. Мини-исследование влияния параметров на производительность

В ходе экспериментальных запусков были протестированы различные значения основных параметров:

- **CorePoolSize и MaxPoolSize:**  
  Увеличение corePoolSize позволяет снизить задержки при поступлении задач за счёт увеличения числа сразу доступных рабочих потоков. Однако если задачи выполняются долго (например, имитируются задержкой 10 секунд), повышение maxPoolSize (при наличии свободных ядер) помогает обработать всплески нагрузки, хотя это и приводит к дополнительным накладным расходам по созданию и уничтожению потоков.

- **QueueSize:**  
  Небольшой размер очереди обеспечивает быстрое переключение между потоками и раннее применение политики отказа (rejected execution), что может быть полезно для критически важных задач, где важно не допустить избыточную задержку. При этом, увеличение размера очереди может помочь аккумулировать задачи при пиковой нагрузке, но при этом может повышаться время ожидания и снижаться отзывчивость.

- **MinSpareThreads и keepAliveTime:**  
  Параметр minSpareThreads позволяет поддерживать заданное минимальное количество простаивающих потоков, обеспечивая быстрый отклик на поступление новых задач. В свою очередь, keepAliveTime регулирует, как долго поток будет простаивать перед завершением, если активность снизилась. 

В итоге, можно сделать вывод, что оптимальные значения параметров напрямую зависят от специфики задачи. 

## 3. Принцип работы механизма распределения задач и балансировки нагрузки

В реализации пула потоков применяется следующая логика распределения задач:

- **Round Robin для выбора воркера:**  
  При вызове метода `execute(Runnable)`, пул перебирает список воркеров в режиме round robin, выбирая следующий индекс (с использованием атомарного счётчика `nextWorkerIndex`). Это обеспечивает равномерное распределение задач между рабочими потоками.

- **Внутренние очереди воркеров:**  
  Каждый воркер имеет собственную фиксированную блокирующую очередь (реализованную как `ArrayBlockingQueue`). При поступлении задачи происходит попытка добавить её в очередь. Если очереди текущего воркера заполнена, метод переходит к следующему воркеру.

- **Порог отказа и политика обработки:**  
  Если ни один из воркеров не смог принять задачу (например, очередь заполнена во всех воркерах), вызывается политика отказа через `RejectedExecutionHandlerImpl`. Это позволяет контролировать поведение при перегрузке и, при необходимости, реализовывать логику повторной отправки или уведомления об отказе.

- **Балансировка и динамическое масштабирование:**  
  Также предусмотрено динамическое добавление новых воркеров при недостатке простаивающих потоков (`idleThreads < minSpareThreads`) и если текущее число активных потоков меньше максимального (`activeThreads < maxPoolSize`). Такой механизм помогает обеспечить необходимый уровень параллелизма в моменты пиковых нагрузок.

Таким образом, механизм распределения задач в пуле основывается на использовании индивидуальных очередей для каждого воркера и схеме round robin, что позволяет достаточно просто и прозрачно балансировать нагрузку между потоками.
